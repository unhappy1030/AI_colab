{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","mount_file_id":"1uU9z-kFI9Qp2Fkl2Zrgb_GTd3wtZTEe-","authorship_tag":"ABX9TyPDtNo+9q7aOCSfooG4Fe63"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yvDne98G4krb"},"outputs":[],"source":["# imports\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# transforms\n","# transform = transforms.Compose(\n","#     [transforms.ToTensor(),\n","#     transforms.Normalize((0.5,), (0.5,))])\n","transform = transforms.Compose(\n","    [transforms.ToTensor()])\n","\n","#transforms.Compose : 여러 전처리 과정을 순서대로 묶어주는 역할\n","#transforms.ToTensor() : Image data를 Tensor를 변환 변환 결과 [0, 255] -> [0, 1.0]\n","#transforms.Normalize() : (x - mean) / std로 변환 mean = 0.5, std = 0.5 변환 결과 [0, 1.0] -> [-1.0, 1.0]\n","\n","#코드 변경해서 정규화 두가지 비교해보기 0~1 , -1~1\n","\n","\n","# datasets 데이터 셋 가져오기\n","trainset = torchvision.datasets.FashionMNIST('./data',\n","    download=True,\n","    train=True,\n","    transform=transform)\n","testset = torchvision.datasets.FashionMNIST('./data',\n","    download=True,\n","    train=False,\n","    transform=transform)\n","\n","# dataloader를 사용하여 학습데이터와 테스트 데이터 설정\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                        shuffle=True, num_workers=2)\n","\n","\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                        shuffle=False, num_workers=2)\n","\n","# constant for classes 10개의 결과 라벨\n","classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n","\n","# helper function to show an image\n","# (used in the `plot_classes_preds` function below)\n","def matplotlib_imshow(img, one_channel=False): #one_channel : 흑백이미지로 처리 할지, 기본적으로 컬러 이미지를 default로 설정\n","    # print(img)\n","    # print(img.shape)\n","    if one_channel:\n","        img = img.mean(dim=0) # img구성 [C, H, W](채널,높이,너비)형태, dim=0 RGB채널의 평균값을 계산하여 단일채널로 압축\n","    img = img / 2 + 0.5     # unnormalize [-1,1] -> [0,1]\n","    npimg = img.numpy()\n","    if one_channel:\n","        plt.imshow(npimg, cmap=\"Greys\")\n","    else:\n","        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 6, 5) #1개의 채널로 입력, 6개 채널로 출력, 필터 사이즈 5x5\n","        #28x28의 이미지를 5x5의 필터로 합성곱 연산을 진행하면 24x24형태의 데이터 6개가 출력 채널로 나오게 된다.\n","        self.pool = nn.MaxPool2d(2, 2)\n","        #특징을 유지하고 가로 세로 사이즈를 줄이는 역할을 한다. 예시에서는 kernel_size, stride를 파라미터로 받는다\n","        #계산 너비,높이 = ((입력크기 + 2 * padding - kernel_size) / stride) + 1\n","        # 24 -> 12\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        #6채널을 16채널로 합성곱 연산을 통한 변환\n","        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 16 * 4 * 4)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","net = Net()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"]},{"cell_type":"code","source":["from torch.utils.tensorboard import SummaryWriter\n","\n","# default `log_dir` is \"runs\" - we'll be more specific here\n","writer = SummaryWriter('runs/fashion_mnist_experiment_1')"],"metadata":{"id":"yHftwW-U5Rk-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = next(dataiter)\n","\n","# create grid of images\n","img_grid = torchvision.utils.make_grid(images)\n","\n","# show images\n","matplotlib_imshow(img_grid, one_channel=True)\n","\n","# write to tensorboard\n","writer.add_image('four_fashion_mnist_images', img_grid)"],"metadata":{"id":"BTeQd6dT5T8G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir=runs"],"metadata":{"collapsed":true,"id":"a8-RCBSxxOCk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir=runs"],"metadata":{"id":"JlLth5q1zXqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["writer.add_graph(net, images)\n","# writer.close()"],"metadata":{"id":"gA6dpEvz6J3L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir=runs"],"metadata":{"id":"IuWrElYmz5Jb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# helper function\n","def select_n_random(data, labels, n=100):\n","    '''\n","    Selects n random datapoints and their corresponding labels from a dataset\n","    '''\n","    assert len(data) == len(labels)\n","\n","    perm = torch.randperm(len(data))\n","    return data[perm][:n], labels[perm][:n]\n","\n","# select random images and their target indices\n","images, labels = select_n_random(trainset.data, trainset.targets)\n","\n","# get the class labels for each image\n","class_labels = [classes[lab] for lab in labels]\n","\n","# log embeddings\n","features = images.view(-1, 28 * 28)\n","writer.add_embedding(features,\n","                    metadata=class_labels,\n","                    label_img=images.unsqueeze(1))\n","# writer.close()"],"metadata":{"id":"HzDEpuDc6hJW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir=runs"],"metadata":{"id":"ntBVpykL5gUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# helper functions\n","\n","def images_to_probs(net, images):\n","    '''\n","    Generates predictions and corresponding probabilities from a trained\n","    network and a list of images\n","    '''\n","    output = net(images)\n","    # convert output probabilities to predicted class\n","    _, preds_tensor = torch.max(output, 1)\n","    preds = np.squeeze(preds_tensor.numpy()) #차원이 1축을 제거하여 배열의 모양을 간소화\n","    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n","\n","\n","def plot_classes_preds(net, images, labels):\n","    '''\n","    Generates matplotlib Figure using a trained network, along with images\n","    and labels from a batch, that shows the network's top prediction along\n","    with its probability, alongside the actual label, coloring this\n","    information based on whether the prediction was correct or not.\n","    Uses the \"images_to_probs\" function.\n","    '''\n","    preds, probs = images_to_probs(net, images)\n","    # plot the images in the batch, along with predicted and true labels\n","    fig = plt.figure(figsize=(12, 48))\n","    for idx in np.arange(4):\n","        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n","        matplotlib_imshow(images[idx], one_channel=True)\n","        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n","            classes[preds[idx]],\n","            probs[idx] * 100.0,\n","            classes[labels[idx]]),\n","                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n","    return fig"],"metadata":{"id":"VpfHBpeccmSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["running_loss = 0.0\n","for epoch in range(1):  # loop over the dataset multiple times\n","\n","    for i, data in enumerate(trainloader, 0):\n","\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        if i % 1000 == 999:    # every 1000 mini-batches...\n","\n","            # ...log the running loss\n","            writer.add_scalar('training loss',\n","                            running_loss / 1000,\n","                            epoch * len(trainloader) + i)\n","\n","            # ...log a Matplotlib Figure showing the model's predictions on a\n","            # random mini-batch\n","            writer.add_figure('predictions vs. actuals',\n","                            plot_classes_preds(net, inputs, labels),\n","                            global_step=epoch * len(trainloader) + i)\n","            running_loss = 0.0\n","print('Finished Training')"],"metadata":{"id":"y2Xp5sdLRt8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir=runs"],"metadata":{"id":"Pbu91-69U0_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir=runs"],"metadata":{"id":"z9w18nG6VIZg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. gets the probability predictions in a test_size x num_classes Tensor\n","# 2. gets the preds in a test_size Tensor\n","# takes ~10 seconds to run\n","class_probs = []\n","class_label = []\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        output = net(images)\n","        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n","\n","        class_probs.append(class_probs_batch)\n","        class_label.append(labels)\n","\n","test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n","test_label = torch.cat(class_label)\n","\n","# helper function\n","def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n","    '''\n","    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n","    precision-recall curve\n","    '''\n","    tensorboard_truth = test_label == class_index\n","    tensorboard_probs = test_probs[:, class_index]\n","\n","    writer.add_pr_curve(classes[class_index],\n","                        tensorboard_truth,\n","                        tensorboard_probs,\n","                        global_step=global_step)\n","    writer.close()\n","\n","# plot all the pr curves\n","for i in range(len(classes)):\n","    add_pr_curve_tensorboard(i, test_probs, test_label)"],"metadata":{"id":"bd88SnV6DVMF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir=runs"],"metadata":{"id":"qZ94YjpHDXOQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd /content/drive/MyDrive/colab_repo/AI_colab"],"metadata":{"id":"YIZ6lzZJHO3x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config"],"metadata":{"id":"WGp9WooL5Npc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add .\n","!git commit -m \"finish the Tensor board part\"\n","!git push origin main"],"metadata":{"id":"WT_Pbd7NHaYy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"twboBmuKH9z0"},"execution_count":null,"outputs":[]}]}